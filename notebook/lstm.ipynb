{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "训练并导出RNN模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import mylib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.061147Z",
     "start_time": "2023-07-21T10:15:29.055625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.061359Z",
     "start_time": "2023-07-21T10:15:29.057183Z"
    }
   },
   "outputs": [],
   "source": [
    "device = mylib.choose_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=28, hidden_size=64, batch_first=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Shape of input is (batch_size,1, 28, 28)\n",
    "        # converting shape of input to (batch_size, 28, 28)\n",
    "        # as required by RNN when batch_first is set True\n",
    "        input = input.reshape(-1,1,1)\n",
    "        output, hidden = self.rnn(input)\n",
    "\n",
    "        # RNN output shape is (seq_len, batch, input_size)\n",
    "        # Get last output of RNN\n",
    "        output = output[:, -1, :]\n",
    "        output = self.batchnorm(output)\n",
    "        output = self.dropout1(output)\n",
    "        output = self.fc1(output)\n",
    "        output = F.relu(output)\n",
    "        output = self.dropout2(output)\n",
    "        output = self.fc2(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.067315Z",
     "start_time": "2023-07-21T10:15:29.061598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/mfp/test_data.csv\", dtype={'v': np.float32},index_col=0,parse_dates=True)\n",
    "print(type(df[['x', 'y']].iloc[0].values[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.082452Z",
     "start_time": "2023-07-21T10:15:29.064358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.086689Z",
     "start_time": "2023-07-21T10:15:29.082602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class FlowSpeedDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.flow_speed = pd.read_csv(csv_file, dtype={'x': np.float32, 'y': np.float32})\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flow_speed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.flow_speed[['x', 'y']].iloc[idx].values\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        return tuple(item)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.086796Z",
     "start_time": "2023-07-21T10:15:29.082761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 28, got 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m StepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.7\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m14\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 16\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     test(model\u001B[38;5;241m=\u001B[39mmodel, device\u001B[38;5;241m=\u001B[39mdevice, test_loader\u001B[38;5;241m=\u001B[39mtest_loader)\n\u001B[1;32m     18\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[33], line 6\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, device, train_loader, optimizer, epoch)\u001B[0m\n\u001B[1;32m      4\u001B[0m data, target \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device), target\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      5\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 6\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(output, target)\n\u001B[1;32m      8\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[31], line 22\u001B[0m, in \u001B[0;36mNet.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# Shape of input is (batch_size,1, 28, 28)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# converting shape of input to (batch_size, 28, 28)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m# as required by RNN when batch_first is set True\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# RNN output shape is (seq_len, batch, input_size)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# Get last output of RNN\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     output \u001B[38;5;241m=\u001B[39m output[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:810\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    806\u001B[0m     \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[1;32m    807\u001B[0m     \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n\u001B[1;32m    808\u001B[0m     hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[0;32m--> 810\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_forward_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    812\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers,\n\u001B[1;32m    813\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:730\u001B[0m, in \u001B[0;36mLSTM.check_forward_args\u001B[0;34m(self, input, hidden, batch_sizes)\u001B[0m\n\u001B[1;32m    725\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_forward_args\u001B[39m(\u001B[38;5;28mself\u001B[39m,  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m    726\u001B[0m                        \u001B[38;5;28minput\u001B[39m: Tensor,\n\u001B[1;32m    727\u001B[0m                        hidden: Tuple[Tensor, Tensor],\n\u001B[1;32m    728\u001B[0m                        batch_sizes: Optional[Tensor],\n\u001B[1;32m    729\u001B[0m                        ):\n\u001B[0;32m--> 730\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_hidden_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[1;32m    732\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[0] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_cell_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[1;32m    734\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[1] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:218\u001B[0m, in \u001B[0;36mRNNBase.check_input\u001B[0;34m(self, input, batch_sizes)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    215\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput must have \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m dimensions, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    216\u001B[0m             expected_input_dim, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()))\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.size(-1) must be equal to input_size. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    220\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: input.size(-1) must be equal to input_size. Expected 28, got 1"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    FlowSpeedDataset(\"../datasets/mfp/train_data.csv\"),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    FlowSpeedDataset(\"../datasets/mfp/test_data.csv\"),\n",
    "    batch_size=1000, shuffle=True)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "for epoch in range(1, 14 + 1):\n",
    "    train(model=model, device=device, train_loader=train_loader, optimizer=optimizer, epoch=epoch)\n",
    "    test(model=model, device=device, test_loader=test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"./output/model/flow_speed_rnn.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:15:29.173412Z",
     "start_time": "2023-07-21T10:15:29.082801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
